#!/usr/bin/python
# -*- coding: utf-8 -*-
__author__ = 'ZS Associates'

"""
Doc_Type         : Business
Description      : The purpose of this code is to execute cleansed layer data type standardization for Laad - 
                   f_sales_account_direct_sales.
Tech_Description : N/A.
Pre_requisites   : Table with cdl_processing_status column post DQM processing should be available.
Inputs           : Batch ID, File ID, Environment
Outputs          : Parquet data in Cleansed layer for Lash - f_sales_account_direct_sales data.
                   Error message (in case of error)
Example          : Parameters replaced in this code
                    {                     
                     pt_batch_id = auto generated by the process
                     pt_file_id = auto generated by the process
                     environment = dev/tst/prd
                    }
Config_File      : PlatformEnvParams.json, EnvCredentials.json
External_Link    : N/A
"""

# Import python packages/libraries
from pyspark.sql import functions as F
from pyspark.sql.functions import *
from pyspark.sql.types import *


# Read the output of dqm engine to data frame
f_sales_account_direct_sales_cleansed_df = spark.table("default.unstitched_f_sales_account_direct_sales_pre_stitch_dqm_$$pt_file_id$$")


# Steps to Implement data type standardization
f_sales_account_direct_sales_cleansed_df = f_sales_account_direct_sales_cleansed_df\
.withColumn("invoice_number",f_sales_account_direct_sales_cleansed_df["invoice_number"].cast("string"))\
.withColumn("line_number",f_sales_account_direct_sales_cleansed_df["line_number"].cast("decimal(36,12)"))\
.withColumn("original_invoice_line_number",f_sales_account_direct_sales_cleansed_df["original_invoice_line_number"].cast("string"))\
.withColumn("sold_to_id",f_sales_account_direct_sales_cleansed_df["sold_to_id"].cast("string"))\
.withColumn("bill_to_id",f_sales_account_direct_sales_cleansed_df["bill_to_id"].cast("string"))\
.withColumn("ship_to_id",f_sales_account_direct_sales_cleansed_df["ship_to_id"].cast("string"))\
.withColumn("payment_term",f_sales_account_direct_sales_cleansed_df["payment_term"].cast("string"))\
.withColumn("payment_term_description",f_sales_account_direct_sales_cleansed_df["payment_term_description"].cast("string"))\
.withColumn("material_number",f_sales_account_direct_sales_cleansed_df["material_number"].cast("string"))\
.withColumn("item_id",f_sales_account_direct_sales_cleansed_df["item_id"].cast("string"))\
.withColumn("invoice_date",f_sales_account_direct_sales_cleansed_df["invoice_date"].cast("timestamp"))\
.withColumn("order_reference",f_sales_account_direct_sales_cleansed_df["order_reference"].cast("string"))\
.withColumn("invoice_amount",f_sales_account_direct_sales_cleansed_df["invoice_amount"].cast("decimal(36,12)"))\
.withColumn("invoice_quantity",f_sales_account_direct_sales_cleansed_df["invoice_quantity"].cast("decimal(36,12)"))\
.withColumn("uom",f_sales_account_direct_sales_cleansed_df["uom"].cast("string"))\
.withColumn("extended_invoice_amount",f_sales_account_direct_sales_cleansed_df["extended_invoice_amount"].cast("decimal(36,12)"))\
.withColumn("contract_id",f_sales_account_direct_sales_cleansed_df["contract_id"].cast("string"))\
.withColumn("contract_base_price",f_sales_account_direct_sales_cleansed_df["contract_base_price"].cast("decimal(36,12)"))\
.withColumn("order_type",f_sales_account_direct_sales_cleansed_df["order_type"].cast("string"))\
.withColumn("reason_code",f_sales_account_direct_sales_cleansed_df["reason_code"].cast("string"))\
.withColumn("sales_order_number",f_sales_account_direct_sales_cleansed_df["sales_order_number"].cast("string"))\
.withColumn("sales_order_line_number",f_sales_account_direct_sales_cleansed_df["sales_order_line_number"].cast("decimal(36,12)"))\
.withColumn("sales_order_date",f_sales_account_direct_sales_cleansed_df["sales_order_date"].cast("timestamp"))\
.withColumn("sales_order_price_date",f_sales_account_direct_sales_cleansed_df["sales_order_price_date"].cast("timestamp"))\
.withColumn("bill_type",f_sales_account_direct_sales_cleansed_df["bill_type"].cast("string"))\
.withColumn("wac",f_sales_account_direct_sales_cleansed_df["wac"].cast("decimal(36,12)"))\
.withColumn("line_reason_code",f_sales_account_direct_sales_cleansed_df["line_reason_code"].cast("string"))\
.withColumn("cdl_source_system_batch_id",f_sales_account_direct_sales_cleansed_df["cdl_source_system_batch_id"].cast("bigint"))


# Reorder columns based on the table structure
f_sales_account_direct_sales_cleansed_df = f_sales_account_direct_sales_cleansed_df.select("cdl_domain","cdl_sub_domain","cdl_data_source","cdl_file_name","cdl_batch_id","cdl_row_id","cdl_year","cdl_semester","cdl_quarter","cdl_month","cdl_week","cdl_day","invoice_number","line_number","original_invoice_line_number","sold_to_id","bill_to_id","ship_to_id","payment_term","payment_term_description","material_number","item_id","invoice_date","order_reference","invoice_amount","invoice_quantity","uom","extended_invoice_amount","contract_id","contract_base_price","order_type","reason_code","sales_order_number","sales_order_line_number","sales_order_date","sales_order_price_date","bill_type","wac","line_reason_code","cdl_source_system_batch_id","cdl_processing_status","cdl_record_load_timestamp","pt_batch_id","pt_file_id")


# Write back parquet files into cleansed table
f_sales_account_direct_sales_cleansed_df.write.mode("overwrite").parquet('s3a://$$cdl_s3_bucket_name$$/cdl/cleansed/f_sales/account/unstitched_f_sales_account_direct_sales/pt_batch_id=$$pt_batch_id$$/pt_file_id=$$pt_file_id$$/')
	
# Metadata refresh command
sqlContext.sql("alter table $$environment$$_cleansed_f_sales.unstitched_f_sales_account_direct_sales "
               "add if not exists partition (pt_batch_id='$$pt_batch_id$$',pt_file_id='$$pt_file_id$$')")
